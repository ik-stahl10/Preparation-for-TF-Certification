{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPBgT2JWcqVQbiOhsrJMk3O"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "CQvAiqFaRBdK"
      },
      "outputs": [],
      "source": [
        "import tensorflow_hub as hub\n",
        "import tensorflow as tf\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "from tensorflow.keras.models import Sequential, Model\n",
        "from tensorflow.keras.layers import Dense, Embedding, Flatten, Bidirectional, LSTM, GRU, Dropout, GlobalAveragePooling1D, Conv1D\n",
        "     "
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data gathering\n"
      ],
      "metadata": {
        "id": "bmygX0gTRLPd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow_datasets as tfds\n",
        "tfds.disable_progress_bar()\n",
        "\n",
        "(ds_train, ds_val), ds_info = tfds.load(\"imdb_reviews\", split=[\"train\", \"test\"], shuffle_files=True, as_supervised=True, with_info=True)\n",
        "ds_info"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H_ndZ335RMs5",
        "outputId": "771bd483-e3f5-4aa1-b5c1-2a7da38b2fc5"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading and preparing dataset 80.23 MiB (download: 80.23 MiB, generated: Unknown size, total: 80.23 MiB) to ~/tensorflow_datasets/imdb_reviews/plain_text/1.0.0...\n",
            "Dataset imdb_reviews downloaded and prepared to ~/tensorflow_datasets/imdb_reviews/plain_text/1.0.0. Subsequent calls will reuse this data.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tfds.core.DatasetInfo(\n",
              "    name='imdb_reviews',\n",
              "    full_name='imdb_reviews/plain_text/1.0.0',\n",
              "    description=\"\"\"\n",
              "    Large Movie Review Dataset.\n",
              "    This is a dataset for binary sentiment classification containing substantially more data than previous benchmark datasets. We provide a set of 25,000 highly polar movie reviews for training, and 25,000 for testing. There is additional unlabeled data for use as well.\n",
              "    \"\"\",\n",
              "    config_description=\"\"\"\n",
              "    Plain text\n",
              "    \"\"\",\n",
              "    homepage='http://ai.stanford.edu/~amaas/data/sentiment/',\n",
              "    data_path='~/tensorflow_datasets/imdb_reviews/plain_text/1.0.0',\n",
              "    file_format=tfrecord,\n",
              "    download_size=80.23 MiB,\n",
              "    dataset_size=129.83 MiB,\n",
              "    features=FeaturesDict({\n",
              "        'label': ClassLabel(shape=(), dtype=tf.int64, num_classes=2),\n",
              "        'text': Text(shape=(), dtype=tf.string),\n",
              "    }),\n",
              "    supervised_keys=('text', 'label'),\n",
              "    disable_shuffling=False,\n",
              "    splits={\n",
              "        'test': <SplitInfo num_examples=25000, num_shards=1>,\n",
              "        'train': <SplitInfo num_examples=25000, num_shards=1>,\n",
              "        'unsupervised': <SplitInfo num_examples=50000, num_shards=1>,\n",
              "    },\n",
              "    citation=\"\"\"@InProceedings{maas-EtAl:2011:ACL-HLT2011,\n",
              "      author    = {Maas, Andrew L.  and  Daly, Raymond E.  and  Pham, Peter T.  and  Huang, Dan  and  Ng, Andrew Y.  and  Potts, Christopher},\n",
              "      title     = {Learning Word Vectors for Sentiment Analysis},\n",
              "      booktitle = {Proceedings of the 49th Annual Meeting of the Association for Computational Linguistics: Human Language Technologies},\n",
              "      month     = {June},\n",
              "      year      = {2011},\n",
              "      address   = {Portland, Oregon, USA},\n",
              "      publisher = {Association for Computational Linguistics},\n",
              "      pages     = {142--150},\n",
              "      url       = {http://www.aclweb.org/anthology/P11-1015}\n",
              "    }\"\"\",\n",
              ")"
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Inspect samples from datasets\n",
        "\n",
        "Binary classification:\n",
        "\n",
        "Negative: 0\n",
        "Positive: 1"
      ],
      "metadata": {
        "id": "hmMH8-tQRREM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "sample = next(iter(ds_train))\n",
        "print(\"Review:\", sample[0].numpy())\n",
        "print(\"Label:\", sample[1].numpy())\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VxStfJpoRSLs",
        "outputId": "acda18a3-c725-4018-afdd-ebe0112da93c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Review: b\"This was an absolutely terrible movie. Don't be lured in by Christopher Walken or Michael Ironside. Both are great actors, but this must simply be their worst role in history. Even their great acting could not redeem this movie's ridiculous storyline. This movie is an early nineties US propaganda piece. The most pathetic scenes were those when the Columbian rebels were making their cases for revolutions. Maria Conchita Alonso appeared phony, and her pseudo-love affair with Walken was nothing but a pathetic emotional plug in a movie that was devoid of any real meaning. I am disappointed that there are movies like this, ruining actor's like Christopher Walken's good name. I could barely sit through it.\"\n",
            "Label: 0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data, train_labels = [], []\n",
        "for review, label in ds_train:\n",
        "  train_data.append(str(review.numpy()))\n",
        "  train_labels.append(label.numpy())\n",
        "\n",
        "val_data, val_labels = [], []\n",
        "for review, label in ds_val:\n",
        "  val_data.append(str(review.numpy()))\n",
        "  val_labels.append(label.numpy())\n",
        "\n",
        "print(\"Number of training samples:\", len(train_data))\n",
        "print(\"Number of validation samples:\", len(val_data))\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pLmQ5iwwRUmE",
        "outputId": "dc3d531b-ce70-4b63-8f74-9761e48bb3f5"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of training samples: 25000\n",
            "Number of validation samples: 25000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Brief analysis to decide proper hparams.\n",
        "\n"
      ],
      "metadata": {
        "id": "_8pxqTLKRbY0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(train_labels).value_counts().plot(kind=\"bar\");\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 262
        },
        "id": "fdhfq2dWRXds",
        "outputId": "a8257b4f-e7f5-48e5-f0ab-1f951d204c8c"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pd.Series(train_data).apply(lambda x : len(x.split())).describe()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mR_d05mwRfoE",
        "outputId": "a4997197-14e6-4360-8279-9578cd3d369b"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "count    25000.000000\n",
              "mean       233.776720\n",
              "std        173.715418\n",
              "min         10.000000\n",
              "25%        127.000000\n",
              "50%        174.000000\n",
              "75%        284.000000\n",
              "max       2470.000000\n",
              "dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "BATCH_SIZE = 64\n",
        "BUFFER_SIZE = 1024\n",
        "VOCAB_SIZE = 1000\n",
        "EMBED_DIM = 64\n",
        "MAX_SEQ_LEN = 256"
      ],
      "metadata": {
        "id": "34Hs84UJRiRd"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Featurizing\n",
        "Tokenizing and padding sequences\n",
        "\n",
        "The average number of tokens persample is 233. Hence, we choose MAX_SEQ_LEN = 256"
      ],
      "metadata": {
        "id": "-vsRkPgURaVF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.preprocessing.text import Tokenizer\n",
        "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
        "\n",
        "tokenizer = Tokenizer(num_words=VOCAB_SIZE, oov_token=\"\")\n",
        "tokenizer.fit_on_texts(train_data)\n",
        "     \n",
        "\n",
        "def create_tfds(tokenizer, X, y, padding=False):\n",
        "  if padding:\n",
        "    X = pad_sequences(tokenizer.texts_to_sequences(X), maxlen=MAX_SEQ_LEN, padding=\"post\")\n",
        "  return tf.data.Dataset.from_tensor_slices((X, y)).shuffle(BUFFER_SIZE).batch(BATCH_SIZE)\n",
        "\n",
        "ds_train = create_tfds(tokenizer, train_data, train_labels, padding=True)\n",
        "ds_val = create_tfds(tokenizer, val_data, val_labels, padding=True)"
      ],
      "metadata": {
        "id": "_kDAUcBuRm9E"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "c6o4EbuORpYL"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential()\n",
        "model.add(Embedding(input_dim=VOCAB_SIZE, input_length=MAX_SEQ_LEN, output_dim=EMBED_DIM))\n",
        "model.add(Conv1D(filters=64, kernel_size=5, activation=\"swish\"))\n",
        "model.add(Dropout(0.2))\n",
        "model.add(GlobalAveragePooling1D())\n",
        "model.add(Dropout(0.2))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sTADtTrzRrNr",
        "outputId": "ec2c7695-b2f6-4516-cd8d-36658c293af0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " embedding (Embedding)       (None, 256, 64)           64000     \n",
            "                                                                 \n",
            " conv1d (Conv1D)             (None, 252, 64)           20544     \n",
            "                                                                 \n",
            " dropout (Dropout)           (None, 252, 64)           0         \n",
            "                                                                 \n",
            " global_average_pooling1d (G  (None, 64)               0         \n",
            " lobalAveragePooling1D)                                          \n",
            "                                                                 \n",
            " dropout_1 (Dropout)         (None, 64)                0         \n",
            "                                                                 \n",
            " dense (Dense)               (None, 1)                 65        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 84,609\n",
            "Trainable params: 84,609\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
        "     \n",
        "\n",
        "callbacks = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=4)\n",
        "model.fit(ds_train, epochs=7, validation_data=ds_val, callbacks=[callbacks]);"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o3CunO1NRvB0",
        "outputId": "1fb53dfe-7eb3-45fc-fda2-4d24344d9d72"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "391/391 [==============================] - 42s 105ms/step - loss: 0.4667 - acc: 0.7902 - val_loss: 0.3499 - val_acc: 0.8512\n",
            "Epoch 2/7\n",
            "391/391 [==============================] - 44s 112ms/step - loss: 0.3469 - acc: 0.8522 - val_loss: 0.3574 - val_acc: 0.8440\n",
            "Epoch 3/7\n",
            "391/391 [==============================] - 40s 101ms/step - loss: 0.3307 - acc: 0.8600 - val_loss: 0.3498 - val_acc: 0.8467\n",
            "Epoch 4/7\n",
            "391/391 [==============================] - 40s 101ms/step - loss: 0.3228 - acc: 0.8666 - val_loss: 0.3263 - val_acc: 0.8591\n",
            "Epoch 5/7\n",
            "391/391 [==============================] - 40s 102ms/step - loss: 0.3152 - acc: 0.8680 - val_loss: 0.3172 - val_acc: 0.8642\n",
            "Epoch 6/7\n",
            "391/391 [==============================] - 40s 102ms/step - loss: 0.3074 - acc: 0.8722 - val_loss: 0.3139 - val_acc: 0.8664\n",
            "Epoch 7/7\n",
            "391/391 [==============================] - 41s 104ms/step - loss: 0.3019 - acc: 0.8740 - val_loss: 0.3158 - val_acc: 0.8640\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Transfer learning vs. pretrained embedding\n"
      ],
      "metadata": {
        "id": "Ly3LWUQ4RxZV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "ds_train = create_tfds(tokenizer, train_data, train_labels, padding=False)\n",
        "ds_val = create_tfds(tokenizer, val_data, val_labels, padding=False)\n",
        "     \n",
        "\n",
        "embedding_url = \"https://tfhub.dev/google/nnlm-en-dim50-with-normalization/2\"\n",
        "\n",
        "model = Sequential()\n",
        "model.add(hub.KerasLayer(embedding_url, input_shape=(), dtype=tf.string, trainable=True))\n",
        "model.add(Dropout(0.4))\n",
        "model.add(Dense(1, activation=\"sigmoid\"))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Go5T_ku2R0fd",
        "outputId": "71a0990a-d4be-4d0c-882f-7d5a50c20bb2"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " keras_layer (KerasLayer)    (None, 50)                48190600  \n",
            "                                                                 \n",
            " dropout_2 (Dropout)         (None, 50)                0         \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 1)                 51        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 48,190,651\n",
            "Trainable params: 48,190,651\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=\"rmsprop\", loss=\"binary_crossentropy\", metrics=[\"acc\"])\n",
        "     \n",
        "\n",
        "callbacks = tf.keras.callbacks.EarlyStopping(monitor=\"val_loss\", patience=4)\n",
        "model.fit(ds_train, epochs=7, validation_data=ds_val, callbacks=[callbacks]);\n",
        "     "
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "d-Tcr9nVR9RM",
        "outputId": "9b47727e-b338-4640-e938-137607e73030"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/7\n",
            "391/391 [==============================] - 115s 293ms/step - loss: 0.4900 - acc: 0.7735 - val_loss: 0.3541 - val_acc: 0.8617\n",
            "Epoch 2/7\n",
            "391/391 [==============================] - 114s 292ms/step - loss: 0.2950 - acc: 0.8830 - val_loss: 0.2841 - val_acc: 0.8836\n",
            "Epoch 3/7\n",
            "391/391 [==============================] - 113s 290ms/step - loss: 0.2354 - acc: 0.9064 - val_loss: 0.2664 - val_acc: 0.8904\n",
            "Epoch 4/7\n",
            "391/391 [==============================] - 114s 291ms/step - loss: 0.2010 - acc: 0.9228 - val_loss: 0.2611 - val_acc: 0.8923\n",
            "Epoch 5/7\n",
            "391/391 [==============================] - 116s 296ms/step - loss: 0.1787 - acc: 0.9326 - val_loss: 0.2615 - val_acc: 0.8915\n",
            "Epoch 6/7\n",
            "391/391 [==============================] - 115s 295ms/step - loss: 0.1641 - acc: 0.9390 - val_loss: 0.2648 - val_acc: 0.8916\n",
            "Epoch 7/7\n",
            "391/391 [==============================] - 116s 297ms/step - loss: 0.1503 - acc: 0.9445 - val_loss: 0.2727 - val_acc: 0.8901\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.evaluate(ds_val)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7VqrONhR9vk",
        "outputId": "2fce2fa8-4472-4d7d-9165-812cd64e5bf8"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "391/391 [==============================] - 27s 70ms/step - loss: 0.2727 - acc: 0.8901\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.2727193236351013, 0.8900799751281738]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    }
  ]
}